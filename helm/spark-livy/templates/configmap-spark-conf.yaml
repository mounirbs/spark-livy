apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-configs
  namespace: {{ .Values.metadata.namespace }}
data:
  spark-defaults.conf: |
    #
    # Licensed to the Apache Software Foundation (ASF) under one or more
    # contributor license agreements.  See the NOTICE file distributed with
    # this work for additional information regarding copyright ownership.
    # The ASF licenses this file to You under the Apache License, Version 2.0
    # (the "License"); you may not use this file except in compliance with
    # the License.  You may obtain a copy of the License at
    #
    #    http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    #

    # Default system properties included when running spark-submit.
    # This is useful for setting default environmental settings.

    # Example:
    spark.master                     spark://spark-master:{{ .Values.sparkMaster.sparkMasterPort }}
    
    #https://spark.apache.org/docs/latest/running-on-kubernetes.html#client-mode-networking
    #https://kubernetes.io/docs/concepts/services-networking/service/#headless-services
    spark.driver.host                apache-livy
    #spark.driver.host
    
    # spark.eventLog.enabled           true
    # spark.eventLog.dir               hdfs://namenode:8021/directory
    # spark.serializer                 org.apache.spark.serializer.KryoSerializer
    spark.driver.memory               {{ .Values.apacheLivy.sparkDriverMemory }}
    # spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

    # Dynamic Allocation
    # Livy considers a dynamic executor one full worker (no concept of cores). So if a worker has 4 cores, one executor for Apache Livy will contain 4 cores
    spark.dynamicAllocation.enabled                 {{ .Values.general.dynamicAllocation.enabled }}
    spark.dynamicAllocation.minExecutors            {{ .Values.general.dynamicAllocation.minExecutors }}
    spark.dynamicAllocation.maxExecutors            {{ .Values.general.dynamicAllocation.maxExecutors }}
    spark.dynamicAllocation.initialExecutors        {{ .Values.general.dynamicAllocation.initialExecutors }}
